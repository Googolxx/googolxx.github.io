<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative Models on Renjie&#39;s log</title>
    <link>http://localhost:1313/categories/generative-models/</link>
    <description>Recent content in Generative Models on Renjie&#39;s log</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 13 Jul 2025 14:45:35 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/generative-models/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Diffusion-Based Generative Models &lt;4&gt;: Fokker-Planck方程</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-4/</link>
      <pubDate>Sun, 13 Jul 2025 14:45:35 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-4/</guid>
      <description>&lt;p&gt;本部分主要介绍Fokker-Planck方程，该方程为Diffusion-Based Generative Models提供了坚实的理论基础。Fokker-Planck方程描述了随机过程中概率密度函数的演化规律，是连接随机微分方程与概率分布的重要桥梁。在扩散模型中，理解Fokker-Planck方程对于分析前向扩散过程和设计反向生成过程至关重要。&lt;/p&gt;&#xA;&lt;p&gt;本部分主要参考了&lt;a href=&#34;https://jiming.site/archives/31/&#34;&gt;Langevin 方程与 Fokker-Planck 方程&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;一-维纳wiener过程&#34;&gt;一. 维纳（Wiener）过程&lt;/h2&gt;&#xA;&lt;p&gt;维纳过程（Wiener Process），也称为布朗运动（Brownian Motion），是随机过程理论中的基础概念，也是理解Fokker-Planck方程的重要前提。&lt;/p&gt;&#xA;&lt;h3 id=&#34;11-维纳过程的定义&#34;&gt;1.1 维纳过程的定义&lt;/h3&gt;&#xA;&lt;p&gt;为了理解维纳过程的本质，我们可以从物理现象出发。考虑一个粒子在直线上进行随机运动，这种运动可以通过离散时间步长的随机游走来建模。&lt;/p&gt;&#xA;&lt;p&gt;设粒子初始位置为 $x=0$，在每个时间步长 $\Delta t$ 内，粒子以相等的概率向左或向右移动距离 $\Delta x$。用 $X(t)$ 表示粒子在时刻 $t$ 的位置，则：&lt;/p&gt;&#xA;$$X(t) = \sum_{i=1}^{N} \eta_i$$&lt;p&gt;其中 $N = t/\Delta t$ 是时间步数，$\eta_i$ 是第 $i$ 步的位移：&lt;/p&gt;&#xA;$$\eta_i = \begin{cases}&#xA;+\Delta x, \text{ 概率为 } 1/2 \\&#xA;-\Delta x, \text{ 概率为 } 1/2&#xA;\end{cases}$$&lt;p&gt;当时间步数 $N$ 很大时，根据中心极限定理，$X(t)$ 的分布将趋近于正态分布。因此，我们只需要计算其均值和方差就能完全确定分布。&lt;/p&gt;&#xA;&lt;p&gt;均值的计算：&lt;/p&gt;&#xA;$$\mathbb{E}[X(t)] = \mathbb{E}\left[\sum_{i=1}^{N} \eta_i\right] = \sum_{i=1}^{N} \mathbb{E}[\eta_i] = N \cdot 0 = 0$$&lt;p&gt;方差的计算：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion-Based Generative Models &lt;3&gt;: SMLD</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-3/</link>
      <pubDate>Thu, 10 Jul 2025 19:28:35 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-3/</guid>
      <description>&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;在生成模型的研究中，基于得分（Score-based）的生成方法提供了一种从目标分布生成数据的新颖而强大的框架。与传统的生成方法不同，这类模型通过估计数据分布的梯度信息——即所谓的得分函数 (Stein&amp;rsquo;s) score function，来指导样本生成过程。&lt;/p&gt;&#xA;&lt;p&gt;其核心思想在于利用统计物理学中的朗之万动力学（Langevin Dynamics）作为采样工具，将随机噪声逐步演化为符合目标分布的样本。&lt;/p&gt;&#xA;&lt;p&gt;尽管在一维情况下，我们可以通过反累积分布函数（CDF）的方法轻松实现采样，但在高维空间中，这种直接方法不再适用。&#xA;此时，Score-based的方法则展现出其独特优势：它通过对概率密度的局部变化进行建模，使得生成过程能够在计算上变得可行，并赋予模型更强的表达能力和灵活性。&lt;/p&gt;&#xA;&lt;p&gt;本部分将介绍(Denosing) Score Matching，并通过 Langevin Dynamics进行采样的算法思想。&#xA;最后给出SMLD (Score Matching with Langevin Dynamics)的算法框架。&lt;/p&gt;&#xA;&lt;h2 id=&#34;二-背景&#34;&gt;二. 背景&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-一维变量的采样&#34;&gt;2.1 一维变量的采样&lt;/h3&gt;&#xA;&lt;p&gt;考虑一种简单情况，$ x \in \mathbb{R}^1 $ 为一维变量，$ x \sim p(x)$，可以通过逆变换采样（Inverse Transform Sampling），从 $ p(x)$进行随机采样，求其累计密度函数 CDF：&lt;/p&gt;&#xA;$$&#xA;F(x) = p(X \leq x)&#xA;$$&lt;p&gt;然后求CDF的逆函数，并从 $[0,1]$ 均匀分布中采样, 代入到CDF的逆函数中，就能实现从分布 $ p(x)$ 中采样：&lt;/p&gt;&#xA;$$&#xA;\begin{aligned}&#xA;u &amp;\sim Uniform[0,1] \\&#xA;x &amp;= F^{-1}(u)&#xA;\end{aligned}&#xA;$$&lt;p&gt;（再回想下VAE中的Reparameterization技巧，从高斯分布 $\mathcal{N}(\mu, \sigma^2)$ 中采样时，是先从标准正态分布 $\mathcal{N}(0, 1)$ 中采样得到 $\mathbf{\epsilon}$，然后通过变换 $x = \mu + \sigma \epsilon$ 得到样本。VAE采用这种技巧的主要目的是解决反向传播时梯度无法通过随机采样节点的问题）&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion-Based Generative Models &lt;2&gt;: DDIM</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-2/</link>
      <pubDate>Tue, 24 Jun 2025 20:08:36 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-2/</guid>
      <description>&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;上一篇内容讲了DDPM的算法框架，看起来一切都很完美，但采样速度还是太慢了，如果设置 $ T=1000$, 那采样的代价还是太大了。因此迎来了DDIM (Denoising Diffusion Implicit Models)。对于DDIM，我觉得还是可以从 DDPM和 SDE/ODE 两个角度去分析的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;11-ddpm视角下的ddim&#34;&gt;1.1 DDPM视角下的DDIM&lt;/h3&gt;&#xA;&lt;h4 id=&#34;核心思想&#34;&gt;核心思想&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt; 是一个基于马尔可夫链的扩散模型，通过逐步加噪（前向过程）和逐步去噪（反向过程）学习数据分布。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt; 是 DDPM 的 &lt;strong&gt;非马尔可夫推广&lt;/strong&gt;，它重新参数化了反向过程，允许 &lt;strong&gt;跳过中间步骤&lt;/strong&gt;，从而加速采样。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;非马尔可夫性&#34;&gt;非马尔可夫性&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt;：前向和反向过程都是马尔可夫的（下一步仅依赖当前步）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt;：通过设计非马尔可夫的逆过程，打破了这一限制，允许更灵活的生成路径（如跳步采样）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;确定性生成&#34;&gt;确定性生成&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt;：反向过程是随机的（每一步注入高斯噪声）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt;：可以通过设定噪声方差为0，实现 &lt;strong&gt;确定性生成&lt;/strong&gt;（类似ODE），从而生成结果可重复。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;采样加速&#34;&gt;采样加速&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DDIM 通过重新参数化，将 DDPM 的 $T$ 步采样压缩到 $S$ 步（$S \ll T$），而保持相似的生成质量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- #### 数学形式&#xA;DDIM 的逆过程改写为：&#xA;$$&#xA;x_{t-1} = \sqrt{\alpha_{t-1}} \left( \frac{x_t - \sqrt{1-\alpha_t} \epsilon_\theta(x_t, t)}{\sqrt{\alpha_t}} \right) + \sqrt{1-\alpha_{t-1}} \epsilon_\theta(x_t, t)&#xA;$$&#xA;其中 $\alpha_t$ 是噪声调度，$\epsilon_\theta$ 是去噪网络。当噪声项系数为0时，生成过程变为确定性。 --&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;12-sdeode视角下的ddim&#34;&gt;1.2 SDE/ODE视角下的DDIM&lt;/h3&gt;&#xA;&lt;h4 id=&#34;核心思想-1&#34;&gt;核心思想&lt;/h4&gt;&#xA;&lt;p&gt;扩散模型可以统一描述为 &lt;strong&gt;随机微分方程（SDE）&lt;/strong&gt; 或 &lt;strong&gt;常微分方程（ODE）&lt;/strong&gt; 的离散化：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion-Based Generative Models &lt;1&gt;: DDPM</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-1/</link>
      <pubDate>Sun, 22 Jun 2025 13:43:59 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-1/</guid>
      <description>&lt;!-- summary = &#34;深入解读去噪扩散概率模型 (DDPM) 的核心算法与数学推导，揭示其如何通过前向加噪与反向去噪过程实现高质量生成。&#34; --&gt;&#xA;&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;扩散模型（&lt;strong&gt;Diffusion Models&lt;/strong&gt;）作为当前生成式 AI 的核心范式，受热力学启发&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，主要思想是迭代地加噪/去噪数据，模拟粒子扩散过程。在图像、视频生成等领域实现了非常好的效果。下文介绍核心代表作之一 &lt;strong&gt;DDPM&lt;/strong&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; (Denoising Diffusion Probabilistic Models)。&lt;/p&gt;&#xA;&lt;p&gt;随着 Diffusion-Based Generative Models 理论的逐渐完善，可以从多种视角（分数匹配、 微分方程等）推导出 DDPM 的前向/逆向扩散过程、优化目标和采样过程。这里，我们将遵循 DDPM 原文的思路进行推导。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;二-ddpm-算法框架&#34;&gt;二. DDPM 算法框架&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-前向扩散过程forward-diffusion-process&#34;&gt;1. 前向扩散过程（Forward Diffusion Process）&lt;/h3&gt;&#xA;&lt;p&gt;前向扩散过程是&lt;em&gt;&lt;strong&gt;无参&lt;/strong&gt;&lt;/em&gt;的扩散过程，服从一个马尔可夫链 (Markov Chain)：马尔科夫链为状态空间中经过从一个状态到另一个状态的转换的随机过程，该过程要求具备&amp;quot;无记忆性&amp;quot;，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。&lt;/p&gt;&#xA;&lt;p&gt;具体来说，从一个真实数据分布采样 $\mathbf{x_0} \sim q(\mathbf{x})$，通过逐步对数据 $\mathbf{x_0}$ 添加高斯噪声（Gaussian Noise），得到被扰动的样本 $\mathbf{x_1},&amp;hellip;\mathbf{x_t},&amp;hellip;\mathbf{x_T}$，在 $T$ 步后接近纯噪声。得益于高斯分布的特殊数学性质，其线性组合仍然是高斯分布，因此可以将加噪过程中互相独立的高斯噪声进行合并:&lt;/p&gt;&#xA;$$&#xA;\begin{aligned}&#xA;\mathbf{x_t} &amp;= \sqrt{\alpha_t} \mathbf{x_{t-1}} + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\&#xA;    &amp;= \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} \right) + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\&#xA;    &amp;= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \underbrace{{\sqrt{\alpha_t} \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} + \sqrt{1 - \alpha_t} \epsilon_{t-1}}}_{\text{Combine noise using linear Gaussian}} \\&#xA;    &amp;= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1} \alpha_t} \bar{\epsilon}_{t-2} \\&#xA;    &amp;=  ... \\&#xA;    &amp;= \sqrt{\bar{\alpha}_t} \mathbf{x_0} +  \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_{t}&#xA;\end{aligned}&#xA;$$&lt;p&gt;其中 $ { \alpha_0, \dots, \alpha_T }$ 是一组人为设置的超参数，用于控制扩散过程中噪声的强度。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
