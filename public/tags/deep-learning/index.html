<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Renjie&#39;s log</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.146.5">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  


    


    
      

    

    
    
      <link href="/tags/deep-learning/index.xml" rel="alternate" type="application/rss+xml" title="Renjie&#39;s log" />
      <link href="/tags/deep-learning/index.xml" rel="feed" type="application/rss+xml" title="Renjie&#39;s log" />
      
    

    
      <link rel="canonical" href="http://localhost:1313/tags/deep-learning/">
    

    <meta property="og:url" content="http://localhost:1313/tags/deep-learning/">
  <meta property="og:site_name" content="Renjie&#39;s log">
  <meta property="og:title" content="Deep-Learning">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="website">

  <meta itemprop="name" content="Deep-Learning">
  <meta itemprop="datePublished" content="2025-06-24T20:08:36+08:00">
  <meta itemprop="dateModified" content="2025-06-24T20:08:36+08:00">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Deep-Learning">

	




<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  window.MathJax  = {
    tex: {
        inlineMath: [['$', '$'], ['\$', '\$']], 
        displayMath: [['$$', '$$']],
        processEnvironments: true,
        
        packages: ['base', 'ams', 'noerrors', 'noundefined'],
        tags: "ams",
    },
    loader:{
        load: ['ui/safe', '[tex]/ams'], 
    
    },
  };
</script>

<link rel="stylesheet" href="/css/custom.css">


  </head><body class="ma0 avenir bg-near-white development">

    

  <header>
    <div class="pb3-m pb6-l bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Renjie&#39;s log
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
          Deep-Learning
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      <p>Below you will find pages that utilize the taxonomy term “Deep-Learning”</p>
    </div>
  </article>
  <div class="mw8 center">
    <section class="flex-ns mt5 flex-wrap justify-around">
      
        <div class="w-100 mb4 relative bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        June 24, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/posts/diffusion-based-generative-models-2/" class="link black dim">
        Diffusion-Based Generative Models &lt;2&gt;: DDIM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h2 id="一-引言">一. 引言</h2>
<p>上一篇内容讲了DDPM的算法框架，看起来一切都很完美，但采样速度还是太慢了，如果设置 $ T=1000$, 那采样的代价还是太大了。因此迎来了DDIM (Denoising Diffusion Implicit Models)。对于DDIM，我觉得还是可以从 DDPM和 SDE/ODE 两个角度去分析的。</p>
<h3 id="11-ddpm视角下的ddim">1.1 DDPM视角下的DDIM</h3>
<h4 id="核心思想">核心思想</h4>
<ul>
<li><strong>DDPM</strong> 是一个基于马尔可夫链的扩散模型，通过逐步加噪（前向过程）和逐步去噪（反向过程）学习数据分布。</li>
<li><strong>DDIM</strong> 是 DDPM 的 <strong>非马尔可夫推广</strong>，它重新参数化了反向过程，允许 <strong>跳过中间步骤</strong>，从而加速采样。</li>
</ul>
<h4 id="非马尔可夫性">非马尔可夫性</h4>
<ul>
<li><strong>DDPM</strong>：前向和反向过程都是马尔可夫的（下一步仅依赖当前步）。</li>
<li><strong>DDIM</strong>：通过设计非马尔可夫的逆过程，打破了这一限制，允许更灵活的生成路径（如跳步采样）。</li>
</ul>
<h4 id="确定性生成">确定性生成</h4>
<ul>
<li><strong>DDPM</strong>：反向过程是随机的（每一步注入高斯噪声）。</li>
<li><strong>DDIM</strong>：可以通过设定噪声方差为0，实现 <strong>确定性生成</strong>（类似ODE），从而生成结果可重复。</li>
</ul>
<h4 id="采样加速">采样加速</h4>
<ul>
<li>DDIM 通过重新参数化，将 DDPM 的 $T$ 步采样压缩到 $S$ 步（$S \ll T$），而保持相似的生成质量。</li>
</ul>
<h4 id="数学形式">数学形式</h4>
<p>DDIM 的逆过程改写为：
</p>
$$
x_{t-1} = \sqrt{\alpha_{t-1}} \left( \frac{x_t - \sqrt{1-\alpha_t} \epsilon_\theta(x_t, t)}{\sqrt{\alpha_t}} \right) + \sqrt{1-\alpha_{t-1}} \epsilon_\theta(x_t, t)
$$<p>
其中 $\alpha_t$ 是噪声调度，$\epsilon_\theta$ 是去噪网络。当噪声项系数为0时，生成过程变为确定性。</p>
<hr>
<h3 id="12-sdeode视角下的ddim">1.2 SDE/ODE视角下的DDIM</h3>
<h4 id="核心思想-1">核心思想</h4>
<p>扩散模型可以统一描述为 <strong>随机微分方程（SDE）</strong> 或 <strong>常微分方程（ODE）</strong> 的离散化：</p>
    </div>
  <a href="/posts/diffusion-based-generative-models-2/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="w-100 mb4 relative bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        June 22, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/posts/diffusion-based-generative-models-1/" class="link black dim">
        Diffusion-Based Generative Models &lt;1&gt;: DDPM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <!-- summary = "深入解读去噪扩散概率模型 (DDPM) 的核心算法与数学推导，揭示其如何通过前向加噪与反向去噪过程实现高质量生成。" -->
<h2 id="一-引言">一. 引言</h2>
<p>扩散模型（<strong>Diffusion Models</strong>）作为当前生成式 AI 的核心范式，受热力学启发<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>，主要思想是迭代地加噪/去噪数据，模拟粒子扩散过程。在图像、视频生成等领域实现了非常好的效果。下文介绍核心代表作之一 <strong>DDPM</strong> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> (Denoising Diffusion Probabilistic Models)。</p>
<p>随着 Diffusion-Based Generative Models 理论的逐渐完善，可以从多种视角（分数匹配、 微分方程等）推导出 DDPM 的前向/逆向扩散过程、优化目标和采样过程。这里，我们将遵循 DDPM 原文的思路进行推导。</p>
<hr>
<h2 id="二-ddpm-算法框架">二. DDPM 算法框架</h2>
<h3 id="1-前向扩散过程forward-diffusion-process">1. 前向扩散过程（Forward Diffusion Process）</h3>
<p>前向扩散过程是<em><strong>无参</strong></em>的扩散过程，服从一个马尔可夫链 (Markov Chain)：马尔科夫链为状态空间中经过从一个状态到另一个状态的转换的随机过程，该过程要求具备&quot;无记忆性&quot;，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。</p>
<p>具体来说，从一个真实数据分布采样 $\mathbf{x_0} \sim q(\mathbf{x})$，通过逐步对数据 $\mathbf{x_0}$ 添加高斯噪声（Gaussian Noise），得到被扰动的样本 $\mathbf{x_1},&hellip;\mathbf{x_t},&hellip;\mathbf{x_T}$，在 $T$ 步后接近纯噪声。得益于高斯分布的特殊数学性质，其线性组合仍然是高斯分布，因此可以将加噪过程中互相独立的高斯噪声进行合并:</p>
$$
\begin{aligned}
\mathbf{x_t} &= \sqrt{\alpha_t} \mathbf{x_{t-1}} + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\
    &= \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} \right) + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\
    &= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \underbrace{{\sqrt{\alpha_t} \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} + \sqrt{1 - \alpha_t} \epsilon_{t-1}}}_{\text{Combine noise using linear Gaussian}} \\
    &= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1} \alpha_t} \bar{\epsilon}_{t-2} \\
    &=  ... \\
    &= \sqrt{\bar{\alpha}_t} \mathbf{x_0} +  \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_{t}
\end{aligned}
$$<p>其中 $ { \alpha_0, \dots, \alpha_T }$ 是一组人为设置的超参数，用于控制扩散过程中噪声的强度。</p>
    </div>
  <a href="/posts/diffusion-based-generative-models-1/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
    </section>
  </div>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/" >
    &copy;  Renjie's log 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
