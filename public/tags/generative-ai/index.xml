<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative-AI on Renjie&#39;s log</title>
    <link>http://localhost:1313/tags/generative-ai/</link>
    <description>Recent content in Generative-AI on Renjie&#39;s log</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 10 Jul 2025 19:28:35 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/generative-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Diffusion-Based Generative Models &lt;3&gt;: SMLD</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-3/</link>
      <pubDate>Thu, 10 Jul 2025 19:28:35 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-3/</guid>
      <description>&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;在生成模型的研究中，基于得分（Score-based）的生成方法提供了一种从目标分布生成数据的新颖而强大的框架。与传统的生成方法不同，这类模型通过估计数据分布的梯度信息——即所谓的得分函数（score function），来指导样本生成过程。其核心思想在于利用统计物理学中的朗之万方程（Langevin equation）作为采样工具，将随机噪声逐步演化为符合目标分布的样本。尽管在一维情况下，我们可以通过反累积分布函数（CDF）的方法轻松实现采样，但在高维空间中，这种直接方法不再适用。&#xA;此时，基于得分的方法则展现出其独特优势：它通过对概率密度的局部变化进行建模，使得生成过程能够在计算上变得可行，并赋予模型更强的表达能力和灵活性。&#xA;本部分将介绍(Denosing) Score Matching，并通过 Langevin Dynamics进行采样的算法思想。&lt;/p&gt;&#xA;&lt;h2 id=&#34;二-相关背景介绍&#34;&gt;二. 相关背景介绍&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-一维变量的采样&#34;&gt;2.1 一维变量的采样&lt;/h3&gt;&#xA;&lt;p&gt;考虑一种简单情况，$ x \in \mathbb{R}^1 $ 为一维变量&lt;/p&gt;&#xA;&lt;h2 id=&#34;三-smld算法框架&#34;&gt;三. SMLD算法框架&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Diffusion-Based Generative Models &lt;2&gt;: DDIM</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-2/</link>
      <pubDate>Tue, 24 Jun 2025 20:08:36 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-2/</guid>
      <description>&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;上一篇内容讲了DDPM的算法框架，看起来一切都很完美，但采样速度还是太慢了，如果设置 $ T=1000$, 那采样的代价还是太大了。因此迎来了DDIM (Denoising Diffusion Implicit Models)。对于DDIM，我觉得还是可以从 DDPM和 SDE/ODE 两个角度去分析的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;11-ddpm视角下的ddim&#34;&gt;1.1 DDPM视角下的DDIM&lt;/h3&gt;&#xA;&lt;h4 id=&#34;核心思想&#34;&gt;核心思想&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt; 是一个基于马尔可夫链的扩散模型，通过逐步加噪（前向过程）和逐步去噪（反向过程）学习数据分布。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt; 是 DDPM 的 &lt;strong&gt;非马尔可夫推广&lt;/strong&gt;，它重新参数化了反向过程，允许 &lt;strong&gt;跳过中间步骤&lt;/strong&gt;，从而加速采样。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;非马尔可夫性&#34;&gt;非马尔可夫性&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt;：前向和反向过程都是马尔可夫的（下一步仅依赖当前步）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt;：通过设计非马尔可夫的逆过程，打破了这一限制，允许更灵活的生成路径（如跳步采样）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;确定性生成&#34;&gt;确定性生成&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDPM&lt;/strong&gt;：反向过程是随机的（每一步注入高斯噪声）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DDIM&lt;/strong&gt;：可以通过设定噪声方差为0，实现 &lt;strong&gt;确定性生成&lt;/strong&gt;（类似ODE），从而生成结果可重复。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;采样加速&#34;&gt;采样加速&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DDIM 通过重新参数化，将 DDPM 的 $T$ 步采样压缩到 $S$ 步（$S \ll T$），而保持相似的生成质量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- #### 数学形式&#xA;DDIM 的逆过程改写为：&#xA;$$&#xA;x_{t-1} = \sqrt{\alpha_{t-1}} \left( \frac{x_t - \sqrt{1-\alpha_t} \epsilon_\theta(x_t, t)}{\sqrt{\alpha_t}} \right) + \sqrt{1-\alpha_{t-1}} \epsilon_\theta(x_t, t)&#xA;$$&#xA;其中 $\alpha_t$ 是噪声调度，$\epsilon_\theta$ 是去噪网络。当噪声项系数为0时，生成过程变为确定性。 --&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;12-sdeode视角下的ddim&#34;&gt;1.2 SDE/ODE视角下的DDIM&lt;/h3&gt;&#xA;&lt;h4 id=&#34;核心思想-1&#34;&gt;核心思想&lt;/h4&gt;&#xA;&lt;p&gt;扩散模型可以统一描述为 &lt;strong&gt;随机微分方程（SDE）&lt;/strong&gt; 或 &lt;strong&gt;常微分方程（ODE）&lt;/strong&gt; 的离散化：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion-Based Generative Models &lt;1&gt;: DDPM</title>
      <link>http://localhost:1313/posts/diffusion-based-generative-models-1/</link>
      <pubDate>Sun, 22 Jun 2025 13:43:59 +0800</pubDate>
      <guid>http://localhost:1313/posts/diffusion-based-generative-models-1/</guid>
      <description>&lt;!-- summary = &#34;深入解读去噪扩散概率模型 (DDPM) 的核心算法与数学推导，揭示其如何通过前向加噪与反向去噪过程实现高质量生成。&#34; --&gt;&#xA;&lt;h2 id=&#34;一-引言&#34;&gt;一. 引言&lt;/h2&gt;&#xA;&lt;p&gt;扩散模型（&lt;strong&gt;Diffusion Models&lt;/strong&gt;）作为当前生成式 AI 的核心范式，受热力学启发&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，主要思想是迭代地加噪/去噪数据，模拟粒子扩散过程。在图像、视频生成等领域实现了非常好的效果。下文介绍核心代表作之一 &lt;strong&gt;DDPM&lt;/strong&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; (Denoising Diffusion Probabilistic Models)。&lt;/p&gt;&#xA;&lt;p&gt;随着 Diffusion-Based Generative Models 理论的逐渐完善，可以从多种视角（分数匹配、 微分方程等）推导出 DDPM 的前向/逆向扩散过程、优化目标和采样过程。这里，我们将遵循 DDPM 原文的思路进行推导。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;二-ddpm-算法框架&#34;&gt;二. DDPM 算法框架&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-前向扩散过程forward-diffusion-process&#34;&gt;1. 前向扩散过程（Forward Diffusion Process）&lt;/h3&gt;&#xA;&lt;p&gt;前向扩散过程是&lt;em&gt;&lt;strong&gt;无参&lt;/strong&gt;&lt;/em&gt;的扩散过程，服从一个马尔可夫链 (Markov Chain)：马尔科夫链为状态空间中经过从一个状态到另一个状态的转换的随机过程，该过程要求具备&amp;quot;无记忆性&amp;quot;，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。&lt;/p&gt;&#xA;&lt;p&gt;具体来说，从一个真实数据分布采样 $\mathbf{x_0} \sim q(\mathbf{x})$，通过逐步对数据 $\mathbf{x_0}$ 添加高斯噪声（Gaussian Noise），得到被扰动的样本 $\mathbf{x_1},&amp;hellip;\mathbf{x_t},&amp;hellip;\mathbf{x_T}$，在 $T$ 步后接近纯噪声。得益于高斯分布的特殊数学性质，其线性组合仍然是高斯分布，因此可以将加噪过程中互相独立的高斯噪声进行合并:&lt;/p&gt;&#xA;$$&#xA;\begin{aligned}&#xA;\mathbf{x_t} &amp;= \sqrt{\alpha_t} \mathbf{x_{t-1}} + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\&#xA;    &amp;= \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} \right) + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\&#xA;    &amp;= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \underbrace{{\sqrt{\alpha_t} \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} + \sqrt{1 - \alpha_t} \epsilon_{t-1}}}_{\text{Combine noise using linear Gaussian}} \\&#xA;    &amp;= \sqrt{\alpha_{t-1} \alpha_t} \mathbf{x_{t-2}} + \sqrt{1 - \alpha_{t-1} \alpha_t} \bar{\epsilon}_{t-2} \\&#xA;    &amp;=  ... \\&#xA;    &amp;= \sqrt{\bar{\alpha}_t} \mathbf{x_0} +  \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_{t}&#xA;\end{aligned}&#xA;$$&lt;p&gt;其中 $ { \alpha_0, \dots, \alpha_T }$ 是一组人为设置的超参数，用于控制扩散过程中噪声的强度。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
